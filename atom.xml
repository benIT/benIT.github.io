<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <title><![CDATA[benIT&#039;s notebook]]></title>
    <link href="/atom.xml" rel="self"/>
    <link href="/"/>
    <updated>2019-02-15T14:44:33+00:00</updated>
    <id>/</id>
        <generator uri="http://sculpin.io/">Sculpin</generator>
            <entry>
            <title type="html"><![CDATA[SSH X11 &amp; docker]]></title>
            <link href="/blog/2019/02/15/ssh-x11-docker"/>
            <updated>2019-02-15T00:00:00+00:00</updated>
            <id>/blog/2019/02/15/ssh-x11-docker</id>
            <content type="html"><![CDATA[<h2 id="purpose">Purpose</h2>

<p>Run GUI application inside a docker container using X11Forwarding.</p>

<p><a href="https://gist.github.com/udkyo/c20935c7577c71d634f0090ef6fa8393">source from github.</a></p>

<h2 id="create-a-container">Create a container</h2>

<h3 id="dockerfile">DockerFile</h3>

<pre><code>FROM ubuntu
RUN apt update \
    &amp;&amp; apt install -y firefox \
                      openssh-server \
                      xauth \
                      emacs \
    &amp;&amp; mkdir /var/run/sshd \
    &amp;&amp; mkdir /root/.ssh \
    &amp;&amp; chmod 700 /root/.ssh \
    &amp;&amp; ssh-keygen -A \
    &amp;&amp; sed -i "s/^.*PasswordAuthentication.*$/PasswordAuthentication no/" /etc/ssh/sshd_config \
    &amp;&amp; sed -i "s/^.*X11Forwarding.*$/X11Forwarding yes/" /etc/ssh/sshd_config \
    &amp;&amp; sed -i "s/^.*X11UseLocalhost.*$/X11UseLocalhost no/" /etc/ssh/sshd_config \
    &amp;&amp; grep "^X11UseLocalhost" /etc/ssh/sshd_config || echo "X11UseLocalhost no" &gt;&gt; /etc/ssh/sshd_config

RUN echo "CONTENT_OF_ID_RSA_PUB_KEY_HERE" &gt;&gt; /root/.ssh/authorized_keys
</code></pre>

<h3 id="build-it">Build it</h3>

<pre><code>docker build -t benit/ubuntu-x11 . --build-arg http_proxy=$http_proxy
</code></pre>

<h2 id="run-container">Run Container</h2>

<pre><code>docker run --name ubuntu-x11 --rm -d -p 2150:22 benit/ubuntu-x11
</code></pre>

<h2 id="ssh-client-configuration">SSH client configuration</h2>

<p>Edit <code>~/.ssh/config</code> on the client, here my workstation is named <code>lxdev</code>:</p>

<pre><code>Host ubuntuX11
     Hostname lxdev
     Port 2150
     user root
     ForwardX11 yes
     ForwardX11Trusted yes
</code></pre>

<h2 id="use-it%21">Use it!</h2>

<pre><code>ssh -X ubuntu-x11 emacs     
</code></pre>

<h2 id="enjoy%21">Enjoy!</h2>

<p><img src="/images/docker/docker-ssh-x11-emacs.png" alt="screenshot" /></p>
]]></content>
        </entry>
            <entry>
            <title type="html"><![CDATA[Linux multiusb live]]></title>
            <link href="/blog/2019/02/15/linux-multiusb-live"/>
            <updated>2019-02-15T00:00:00+00:00</updated>
            <id>/blog/2019/02/15/linux-multiusb-live</id>
            <content type="html"><![CDATA[<h2 id="purpose">Purpose</h2>

<p>This post deals with creating a multi linux iso live usb drive. <a href="https://itsfoss.com/multiple-linux-one-usb/">source</a></p>

<h2 id="procedure">Procedure</h2>

<ul>
<li>format your drive to fat32</li>
<li><a href="https://github.com/mbusb/multibootusb/releases/download/v8.8.0/python3-multibootusb_8.8.0-1_all.deb">download MultiBootUsb</a></li>
<li>install it : <code>dpkg -i python3-multibootusb_8.8.0-1_all.deb</code></li>
<li>check if all python dependencies are satisfied, if not try install missing with <code>sudo apt install python3-pyqt5 p7zip-full python3-pyudev</code></li>
<li>enjoy : you can now burn several iso using the GUI. Great tool!</li>
</ul>
]]></content>
        </entry>
            <entry>
            <title type="html"><![CDATA[Linux logs]]></title>
            <link href="/blog/2019/02/11/linux-mastering-logs"/>
            <updated>2019-02-11T00:00:00+00:00</updated>
            <id>/blog/2019/02/11/linux-mastering-logs</id>
            <content type="html"><![CDATA[<h2 id="purpose">Purpose</h2>

<p>The aim of is post is to manipulate linux system logs.</p>

<p>Logging is an important part of IT system and must be understand.</p>

<h2 id="test-program">Test program</h2>

<p>The following program named <code>program.sh</code> is used to test log services:</p>

<pre><code>echo I am $(whoami) and up from  $(uptime)
</code></pre>

<h2 id="logs">Logs</h2>

<p>Logs are managed with a service named <code>rsyslog</code></p>

<pre><code>sudo service rsyslog status
</code></pre>

<h2 id="activate-cron-log">Activate cron log</h2>

<p>In <code>sudo vim /etc/rsyslog.conf</code>, uncomment this line:</p>

<pre><code>cron.*                          /var/log/cron.log
</code></pre>

<p>Restart <code>systemctl</code>:</p>

<pre><code>sudo systemctl restart rsyslog
</code></pre>

<p>This doesn't log your program output, but logs your cron information.</p>

<p>Considering the following crontab that runs every minute:</p>

<pre><code>* * * * * /home/debian/prog.sh
</code></pre>

<p>Let's check <code>cron.log</code> details:</p>

<pre><code>sudo tail -f /var/log/cron.log

Feb 11 10:09:01 sandbox CRON[25182]: (root) CMD (  [ -x /usr/lib/php/sessionclean ] &amp;&amp; if [ ! -d /run/systemd/system ]; then /usr/lib/php/sessionclean; fi)
Feb 11 10:09:01 sandbox CRON[25183]: (debian) CMD (/home/debian/prog.sh)
Feb 11 10:10:01 sandbox CRON[25243]: (debian) CMD (/home/debian/prog.sh)
Feb 11 10:11:01 sandbox CRON[25373]: (debian) CMD (/home/debian/prog.sh)
Feb 11 10:12:01 sandbox CRON[25396]: (debian) CMD (/home/debian/prog.sh)
Feb 11 10:13:01 sandbox CRON[25405]: (debian) CMD (/home/debian/prog.sh)
Feb 11 10:14:01 sandbox CRON[25415]: (debian) CMD (/home/debian/prog.sh)
Feb 11 10:15:01 sandbox CRON[25439]: (root) CMD (command -v debian-sa1 &gt; /dev/null &amp;&amp; debian-sa1 1 1)
Feb 11 10:15:01 sandbox CRON[25441]: (debian) CMD (/home/debian/prog.sh)
Feb 11 10:16:02 sandbox CRON[25459]: (debian) CMD (/home/debian/prog.sh)
</code></pre>

<h2 id="log-rotation">Log rotation</h2>

<p>Log rotation is managed with a service named <code>logrotate</code></p>

<pre><code>cat /var/lib/logrotate/status | grep apache

"/var/log/apache2/access.log" 2019-2-8-6:25:2
"/var/log/apache2/other_vhosts_access.log" 2018-5-29-6:0:0
"/var/log/apache2/error.log" 2019-2-11-6:25:1
</code></pre>

<p>Let's check apache2 webserver log rotation configuration :</p>

<pre><code>cat /etc/logrotate.d/apache2 
/var/log/apache2/*.log {
    daily
    missingok
    rotate 14
    compress
    delaycompress
    notifempty
    create 640 root adm
    sharedscripts
    postrotate
            if /etc/init.d/apache2 status &gt; /dev/null ; then \
                /etc/init.d/apache2 reload &gt; /dev/null; \
            fi;
    endscript
    prerotate
        if [ -d /etc/logrotate.d/httpd-prerotate ]; then \
            run-parts /etc/logrotate.d/httpd-prerotate; \
        fi; \
    endscript
}
</code></pre>

<h2 id="example-with-%60program.sh%60">Example with <code>program.sh</code></h2>

<h3 id="program-log-location">Program log location</h3>

<p>We will tell our program to write here: <code>/var/log/prog.sh/log</code>. Let's create this file with the right permissions:</p>

<pre><code>sudo mkdir /var/log/prog.sh/
sudo touch /var/log/prog.sh/log
sudo chmod ugo+rw /var/log/prog.sh/log
</code></pre>

<h3 id="program-crontab">Program crontab</h3>

<pre><code>* * * * * /home/debian/prog.sh &gt;&gt; /var/log/prog.sh/log
</code></pre>

<h3 id="program-log-rotation">Program log rotation</h3>

<p>Edit <code>/etc/logrotate.d/program.sh</code> :</p>

<pre><code>/var/log/program.sh/*.log {
        daily
        missingok
        rotate 5
        compress
        delaycompress
        notifempty
        create 644 root root
}
</code></pre>

<p><a href="https://doc.ubuntu-fr.org/logrotate#exemple">Great doc here</a>.</p>

<h3 id="check-log-rotation">Check log rotation</h3>

<pre><code>ls /var/log/prog.sh/
</code></pre>

<h2 id="another-example-with-a-cronjob-from-a-webapp-named-%60moodle%60">Another example with a cronjob from a webapp named <code>moodle</code></h2>

<h3 id="moodle-log-location">Moodle log location</h3>

<pre><code>sudo mkdir /var/log/moodle
sudo touch /var/log/moodle/cron.log
sudo chmod -R ug+rw /var/log/moodle/
</code></pre>

<h3 id="moodle-crontab">Moodle crontab</h3>

<p>This job must be run from <code>www-data</code> user, so we need the crontab too to be run from <code>www-data</code> user:</p>

<pre><code>sudo crontab -u www-data -e
</code></pre>

<p>edit as follow:</p>

<pre><code>#run moodle cron every hour
0 * * * * php /data/moodle/admin/cli/cron.php &gt;&gt; /var/log/moodle/cron.log 2&gt;&amp;1
</code></pre>

<p><strong>Important stderr has been redirected to stdout with <code>2&amp;1</code></strong> and all that is printed in a file.</p>

<h3 id="moodle-log-rotation">Moodle log rotation</h3>

<p>Edit <code>/etc/logrotate.d/moodle</code> :</p>

<pre><code>/var/log/moodle/*.log {
        daily
        missingok
        rotate 5
        compress
        delaycompress
        notifempty
        create 640 www-data www-data
}    
</code></pre>
]]></content>
        </entry>
            <entry>
            <title type="html"><![CDATA[How to make a christmas garland with a nginx reverse proxy and 3 apache backends under docker?]]></title>
            <link href="/blog/2019/01/25/docker-make-a-christmas-garland-with-nginx-apache"/>
            <updated>2019-01-25T00:00:00+00:00</updated>
            <id>/blog/2019/01/25/docker-make-a-christmas-garland-with-nginx-apache</id>
            <content type="html"><![CDATA[<h1 id="purpose">Purpose</h1>

<p>This posts deals with doing yourself a christmas garland!</p>

<p>We will be using :</p>

<ul>
<li>nginx as a reverse proxy</li>
<li>apache as a backend</li>
<li>docker as a plateforme  </li>
</ul>

<h1 id="repository">Repository</h1>

<p><a href="https://github.com/benIT/docker-nginx-reverse-proxy">You will find a demonstration repository here.</a></p>

<h1 id="demo">Demo</h1>

<p><a href="/video/docker-christmas-garland-demo.mp4">A video is available here.</a></p>

<p>If it does not work, download it from github repo:</p>

<pre><code>wget https://raw.githubusercontent.com/benIT/docker-nginx-reverse-proxy/master/demo.mp4
vlc demo.mp4
</code></pre>

<h1 id="conclusion">Conclusion</h1>

<p>Never forget that computing should always be fun!</p>
]]></content>
        </entry>
            <entry>
            <title type="html"><![CDATA[Docker 101: docker-compose]]></title>
            <link href="/blog/2019/01/15/docker-docker-compose"/>
            <updated>2019-01-15T00:00:00+00:00</updated>
            <id>/blog/2019/01/15/docker-docker-compose</id>
            <content type="html"><![CDATA[<h1 id="docker-compose">Docker compose</h1>

<p>Purpose: compose is a tool designed to create multi-containers app.</p>

<h2 id="install">Install</h2>

<pre><code>sudo apt install python-pip
pip install docker-compose
</code></pre>

<h2 id="docker-compose.yml">docker-compose.yml</h2>

<p>The magic happens in a file named <code>docker-compose.yml</code></p>

<h2 id="run">Run</h2>

<pre><code>docker-compose up -d
</code></pre>

<h2 id="stop">Stop</h2>

<pre><code>docker-compose down -v
</code></pre>

<h2 id="networking">Networking</h2>

<p><code>docker-compose</code> handles the creation a private network:</p>

<pre><code>Creating network "n-tiers_default" with the default driver
Creating object-cache ... done
Creating pgsql        ... done
Creating web          ... done
</code></pre>

<h1 id="example">Example</h1>

<p>Better than words, take a look at this <a href="https://github.com/benIT/docker-compose-n-tiers">repo that illustrates a classical n-tiers web app</a></p>
]]></content>
        </entry>
            <entry>
            <title type="html"><![CDATA[Docker 101: networking]]></title>
            <link href="/blog/2019/01/14/docker-networking"/>
            <updated>2019-01-14T00:00:00+00:00</updated>
            <id>/blog/2019/01/14/docker-networking</id>
            <content type="html"><![CDATA[<h1 id="docker-running-containers-inside-a-bridge-network">Docker running containers inside a bridge network</h1>

<p>The purpose of this post is to isolate each tiers of our app into different containers.</p>

<p>We will create a private network and run containers inside this private network.</p>

<p><a href="https://docker-curriculum.com/#webapps-with-docker">This article is largely inspired by this great resource.</a></p>

<h2 id="networking">Networking</h2>

<h3 id="create-an-isolated-private-bridge-network">Create an isolated private bridge network</h3>

<pre><code>docker network create web-net    
</code></pre>

<h3 id="inspect-the-private-network">Inspect the private network</h3>

<pre><code>docker network inspect web-net
</code></pre>

<h3 id="run-a-container-inside-the-private-bridge-network-with-%60--net%60-option">Run a container inside the private bridge network with <code>--net</code> option</h3>

<pre><code>docker run --name pgsql-web --rm  -d --net web-net postgres:latest
docker run --name debian-web --rm -p 80:80 --net web-net -d benit/debian-web:latest
</code></pre>

<h3 id="inspect-the-private-network-to-get-ips-of-containers-of-the-private-network">Inspect the private network to get IPs of containers of the private network</h3>

<pre><code>docker network inspect web-net
</code></pre>

<p>gives:</p>

<pre><code> "Containers": {
            "3729ccbb14e514fd6c8b571ed9c985c28293cb5bfdb10c6c233773f50d6ba763": {
                "Name": "debian-web",
                "EndpointID": "c370cab93cdd2ac9f30f568a1709b8c998d2ca36106d5423b484a20aadbff84f",
                "MacAddress": "02:42:ac:12:00:03",
                "IPv4Address": "172.18.0.3/16",
                "IPv6Address": ""
            },
            "61bcf5cd9838c8c2e66beef73a04a2704a3be7e2085a5c6b4ad58bd78f12a138": {
                "Name": "pgsql-web",
                "EndpointID": "128f50ead4974a725c04551cb284fec2c733a48375a4819096b0b623ff2af4ac",
                "MacAddress": "02:42:ac:12:00:02",
                "IPv4Address": "172.18.0.2/16",
                "IPv6Address": ""
            }
        },
</code></pre>

<h2 id="putting-it-all-together">Putting it all together</h2>

<h3 id="let%27s-create-a-database">Let's create a database</h3>

<pre><code>docker container exec pgsql-web psql -U postgres -c "create database webapp";
docker container exec pgsql-web psql -U postgres -d webapp -c "CREATE TABLE account(user_id serial PRIMARY KEY,username VARCHAR (50) UNIQUE NOT NULL,created_on TIMESTAMP NOT NULL);" ;
docker container exec pgsql-web psql -U postgres -d webapp -c "INSERT INTO account (username,created_on ) VALUES ('foo','2019-01-01') ;" ;
docker container exec pgsql-web psql -U postgres -d webapp -c "INSERT INTO account (username,created_on ) VALUES ('bar','2019-01-02') ;" ;
</code></pre>

<h3 id="connect-database-container-from-webserver-container">Connect database container from webserver container</h3>

<pre><code>docker container exec -it debian-web  psql -U postgres -h 172.18.0.2 -d webapp -c "select * from account;" ;
</code></pre>

<p>gives:</p>

<pre><code> user_id | username |     created_on      
---------+----------+---------------------
       1 | foo      | 2019-01-01 00:00:00
       2 | bar      | 2019-01-02 00:00:00
(2 rows)
</code></pre>
]]></content>
        </entry>
            <entry>
            <title type="html"><![CDATA[Docker 101: Dockerfile]]></title>
            <link href="/blog/2019/01/14/docker-dockerfile"/>
            <updated>2019-01-14T00:00:00+00:00</updated>
            <id>/blog/2019/01/14/docker-dockerfile</id>
            <content type="html"><![CDATA[<h1 id="dockerfile">Dockerfile</h1>

<p>A <code>Dockerfile</code> is a text document that contains all the commands a user could call on the command line to assemble an image.</p>

<h2 id="example">Example</h2>

<p>You will find <a href="https://github.com/benIT/debian-web">in this repo</a> a running <code>Dockerfile</code>  based on a debian image that runs an Apache webserver.</p>

<p>You will find <a href="https://github.com/benIT/debian-web/blob/master/README.md">in this file</a> all the base commands to manage a <code>Dockerfile</code> .</p>
]]></content>
        </entry>
            <entry>
            <title type="html"><![CDATA[Wordpress migration procedure]]></title>
            <link href="/blog/2018/04/27/wordpress-migration-procedure"/>
            <updated>2018-04-27T00:00:00+00:00</updated>
            <id>/blog/2018/04/27/wordpress-migration-procedure</id>
            <content type="html"><![CDATA[<h2 id="extract-source-site-filesystem">Extract source site filesystem</h2>

<pre><code>tar -czf mySite.tgz /var/www/mySite
</code></pre>

<h2 id="extract-source-site-database">Extract source site database</h2>

<pre><code>mysqldump -u mySite -p mySite &gt; mySite.sql
</code></pre>

<h2 id="transfert-source-fs-and-db-to-target-site">Transfert source fs and db to target site</h2>

<ul>
<li><p>Extract tar archive</p>

<pre><code>tar -czf mySite.tgz
</code></pre></li>
<li><p>Import database</p></li>
</ul>

<h2 id="migrate-database">Migrate database</h2>

<p>Wordpress stores url in database, some of them can be serialized so wa can't just replace them with a bash script.</p>

<p>The best and easier way is to use this project <a href="https://github.com/interconnectit/Search-Replace-DB">interconnectit/Search-Replace-DB</a> :</p>

<ul>
<li>download it</li>
<li>upload it to the wordpress root</li>
<li>open a browser at the matching url</li>
<li>fill the form to migrate your database</li>
</ul>
]]></content>
        </entry>
            <entry>
            <title type="html"><![CDATA[Install keepass and kee on linux]]></title>
            <link href="/blog/2018/02/23/keepass-kee-linux"/>
            <updated>2018-02-23T00:00:00+00:00</updated>
            <id>/blog/2018/02/23/keepass-kee-linux</id>
            <content type="html"><![CDATA[<h2 id="install-keepass2">install keepass2</h2>

<pre><code>sudo add-apt-repository ppa:jtaylor/keepass
sudo apt-get update &amp;&amp; sudo apt-get install keepass2
</code></pre>

<h2 id="install-firefox-addon-%27kee%27">install firefox addon 'kee'</h2>

<ul>
<li><a href="https://addons.mozilla.org/fr/firefox/addon/keefox/?src=search">download it here</a></li>
<li><a href="https://github.com/kee-org/KeeFox/wiki/en-|-Getting-started#linux">kee doc here</a> with linux keepass requirement.</li>
</ul>

<h2 id="download-keepassrpc.plgx-plugin">download KeePassRPC.plgx plugin</h2>

<p><a href="https://github.com/kee-org/keepassrpc/releases">download KeePassRPC.plgx plugin</a></p>

<pre><code>sudo mkdir /usr/lib/keepass2/plugins
sudo cp 'KeePassRPC.plgx' '/usr/lib/keepass2/plugins/'
sudo apt-get install mono-complete
</code></pre>

<h2 id="restart-keepass-and-firefox">Restart keepass and firefox</h2>

<p>you should be prompt about kee to authorize keepass</p>
]]></content>
        </entry>
            <entry>
            <title type="html"><![CDATA[mySQL to postgreSQL schema conversion]]></title>
            <link href="/blog/2018/01/22/mysql-2-pgsql-conversion"/>
            <updated>2018-01-22T00:00:00+00:00</updated>
            <id>/blog/2018/01/22/mysql-2-pgsql-conversion</id>
            <content type="html"><![CDATA[<h2 id="purpose">Purpose</h2>

<p>I was looking for a tool that convert a mysql db to a pgsql one.
<a href="https://github.com/philipsoutham/py-mysql2pgsql">philipsoutham/py-mysql2pgsql</a> does the trick and saved my day!</p>

<h2 id="install">Install</h2>

<pre><code>sudo apt-get install python-pip
pip install py-mysql2pgsql
</code></pre>

<h2 id="configure">Configure</h2>

<p>Edit configuration in <code>mysql2pgsql.yml</code></p>

<pre><code># if a socket is specified we will use that
# if tcp is chosen you can use compression
mysql:
 hostname: localhost
 port: 3306
 socket: /var/run/mysqld/mysqld.sock
 #socket: /tmp/mysql.sock
 username: emedia
 password: emedia
 database: emedia
 compress: false
destination:
 # if file is given, output goes to file, else postgres
 file: /vagrant/shared/migrationMysql2Pgsql.sql
 postgres:
  hostname: localhost
  port: 5432
  username: mysql2psql
  password:
  database: mysql2psql_test

# if tables is given, only the listed tables will be converted.  leave empty to convert all tables.
only_tables:
- lti2_consumer
- lti2_context
- lti2_nonce
- lti2_resource_link
- lti2_share_key
- lti2_tool_proxy
- lti2_user_result
# if exclude_tables is given, exclude the listed tables from the conversion.
#exclude_tables:
#- table3
#- table4

# if supress_data is true, only the schema definition will be exported/migrated, and not the data
supress_data: true

# if supress_ddl is true, only the data will be exported/imported, and not the schema
supress_ddl: false

# if force_truncate is true, forces a table truncate before table loading
force_truncate: false
</code></pre>
]]></content>
        </entry>
    </feed>